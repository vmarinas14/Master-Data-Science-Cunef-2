---
title: "PRACTICA  REGULARIZACION"
author: "Victor Marinas"
date: "15/10/2019"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
#Instalamos las librerias necesarias

library(rsample)
library(glmnet) 
library(dplyr)  
library(ggplot2)
library(nortest)
library(readr)
library(ISLR)
library(leaps)
library(caret)
```



```{r}
#Importamos la base de datos

datos_nba  <- read_csv("~/Victor/Cunef/Prediccion/nba.csv")


```



```{r}
## Renombramos las variables  ##

datos_nba<-rename(datos_nba,"Jugador"="Player","Salario"="Salary",'Pais'='NBA_Country','Numero_Draft'="NBA_DraftNumber", "Edad"="Age", "Equipo"="Tm", "Partidos_Jugados"="G", "Minutos_Jugados"="MP", "Eficiencia_Jugador"="PER", "Acierto_Tiro"="TS%", "Intento_Triples"="3PAr", "Intento_Libres"="FTr", "Rebotes_Ofensivos"="ORB%", "Rebotes_Defensivos"="DRB%", "Rebotes_Totales"="TRB%", "Asistencias"="AST%", "Steals"="STL%" , "Chapas"="BLK%", "Perdidas_Balon"="TOV%", "Victorias_Ofensivas"="OWS", "Victorias_Defensivas"="DWS", "Puntos_OfensivosVSMedia"="OBPM", "Puntos_DefensivosVSMedia"="DBPM", "PuntosVSMedia"="BPM", "PuntosVSMedia_Competidor_Directo"="VORP")

```

#el objetivo es explicar la variable dependiente salario, que depende de las variables independientes o exogenas

```{r}
## Comprobacion de variables inutilizables con la siguiente funcion

1 - (sum(complete.cases(datos_nba)) / nrow(datos_nba))
```



```{r}
#Eliminamos las varibales duplicadas y los NA

datos_nba <- unique(datos_nba)

datos_nba <- na.omit(datos_nba)
```





```{r}
#Muestra de nombres#
names(datos_nba)
```



```{r}
#Tipos de variables (ESTRUCTURA)
str(datos_nba)
```



```{r}
## Dimension de los datos de 28 a 483 ##
dim(datos_nba)
```



```{r}
## MODELOS PREDICTIVOS ## modelo best
#Borro las variables Jugador, Equipo y país, ya que no son variables reelevantes, por lo que nos quedan 24 variables independientes y una variable dependiente que es el Salario


mejor_modelo <- regsubsets(Salario~.- Jugador - Pais - Equipo, data = datos_nba, nvmax = 24)
summary(mejor_modelo)
```



```{r}
## Una vez identificado el mejor modelo de cada tamaño, se tiene que escoger el mejor de entre todos ellos. ##
names(summary(mejor_modelo))
```


```{r}
# Hacemnos el R cuadrado Ajustado, esta variable cuanto mas proximo a 1, más preciso es. Podemos ver que con 11 variables el R2 es optimo, con un valor de 0,53


summary(mejor_modelo)$adjr2
```



```{r}
#Se identifica que modelo tiene el valor máximo de R ajustado, El modelo que ocupa la posición 11 es el que mayor R2ajustado (es decir con 11 variables)

which.max(summary(mejor_modelo)$adjr2)
```



```{r}
## REPRESENTACION GRAFICA DEL ESTADISTICOESCOGIDO PARA COMPARAR LOS MODELOS ##
#Una representación gráfica del estadístico escogido para comparar los modelos, en este caso R2ajustado
#frente al número de predictores permite evaluar la evolución de la precisión del modelo en función del tamaño y si la #mejora es sustancial.

p <- ggplot(data = data.frame(n_predictores = 1:24,
                              R_ajustado = summary(mejor_modelo)$adjr2),
            aes(x = n_predictores, y = R_ajustado)) +
    geom_line() +
    geom_point()

#Se identifica en rojo el máximo
p <- p + geom_point(aes(
                    x = n_predictores[which.max(summary(mejor_modelo)$adjr2)],
                    y = R_ajustado[which.max(summary(mejor_modelo)$adjr2)]),
                    colour = "red", size = 3)
p <- p +  scale_x_continuous(breaks = c(0:24)) + 
          theme_bw() +
          labs(title = 'R2_ajustado vs número de predictores', 
               x =  'número predictores')
p

```



```{r}
#Coeficientes del modelo y su estimacion


coef(object = mejor_modelo, id = 11)

```
```{r}
summary(mejor_modelo)$adjr2[11]
```


```{r}
## K-CROSS-VALIDATION ##

set.seed(11)

# Sample() mezcla aleatoriamente las posiciones, crea 10 grupos
# Es importante que la asignación sea aleatoria
grupo <- sample(rep(x = 1:10, length = nrow(datos_nba))) 

#Se comprueba que la distribución es aproximadamente equitativa
table(grupo)
```



```{r}

## PREDICCIONES DE CADA UNO DE LOS MODELOS ##
predict.regsubsets  <- function(object, newdata, id, ...){
    # Extraer la fórmula del modelo (variable dependiente ~ predictores)
    form <- as.formula(object$call[[2]])
    # Generar una matriz modelo con los nuevos datos y la fórmula
    mat <- model.matrix(form, newdata)
    # Extraer los coeficientes del modelo
    coefi <- coef(object , id = id)
    # Almacenar el nombre de las variables predictoras del modelo
    xvars <- names(coefi)
    # Producto matricial entre los coeficientes del modelo y los valores de
    # los predictores de las nuevas observaciones para obtener las 
    # predicciones
    mat[ , xvars] %*% coefi
}


# Matriz que almacena los test-error estimados. Cada columna representa un
# modelo. Cada fila representa uno de los 10 grupos en los que se han dividido
# las observaciones.
error_matrix <- matrix(data = NA, nrow = 10, ncol = 24,
                       dimnames = list(NULL, c(1:24)))

# Loop en el que se excluye en cada iteración un grupo distinto
# ESTE LOOP ESTA HECHO PARA UN DATA FRAME CON 24 PREDICTORES
num_validaciones <- 10
num_predictores <- 24

for (k in 1:num_validaciones) {
  # Identificación de datos empleados como training
  train <- datos_nba[grupo != k, ]
  # Selección de los mejores modelos para cada tamaño basándose en RSS
  mejor_modelo <- regsubsets(Salario~. - Jugador - Pais - Equipo, data = train, nvmax = 24,
                                method = "forward")
 
  # Para cada uno de los modelos "finalistas" se calcula el test-error con
  # el grupo excluido
  for (i in 1:num_predictores) {
    test <- datos_nba[grupo == k, ]
    # Las predicciones del modelo i almacenado en el objeto regsubsets se
    # extraen mediante la función predict.regsubsets() definida arriba
    predicciones <- predict.regsubsets(object = mejor_modelo,
                                       newdata = test, id = i)
    # Cálculo y almacenamiento del MSE para el modelo i
    error_matrix[k,i] <- mean((test$Salario - predicciones)^2)
  }
}
```



```{r}
mean_cv_error <- apply(X = error_matrix, MARGIN = 2, FUN = mean)
# plot(sqrt(mean_cv_error), type = "b", pch = 24)
which.min(x = mean_cv_error)
```
```{r}

ggplot(data = data.frame(n_predictores = 1:24, mean_cv_error = mean_cv_error),
       aes(x = n_predictores, y = mean_cv_error)) +
  geom_line() +
  geom_point() +
  geom_point(aes(x = n_predictores[which.min(mean_cv_error)],
                 y = mean_cv_error[which.min(mean_cv_error)]),
             colour = "red", size = 3) +
  scale_x_continuous(breaks = c(0:24)) +
  theme_bw() +
  labs(title = "Cross-validation mean error vs número de predictores",
       x = "número predictores")


#COMO HEMOS COMENTADO ANTERIORMENTE LA MEJOR PREDICCION SE HACE CON 8 VARIABLES
```



```{r}
## EL MEJOR MODELO POR 10 CROSS VALIDATION ESTA FORMADO POR 8 PREDICTORES ##

modelo_final <- regsubsets(Salario~. -Jugador -Pais -Equipo, data = datos_nba, nvmax = 24,
                           method = "forward")
coef(object = modelo_final, 8)


```



```{r}
## ELASTIC NET ##

set.seed(123)
nba_split <- initial_split(datos_nba, prop = .7, strata = "Salario")
nba_train <- training(nba_split)
nba_test  <- testing(nba_split)
```


```{r}
# Creamos las matrices de entrenamiento y test
nba_train_x <- model.matrix(Salario ~ . - Jugador - Pais - Equipo, nba_train)[, -1]
nba_train_y <- log(nba_train$Salario)

nba_test_x <- model.matrix(Salario ~ .- Jugador - Pais - Equipo, nba_test)[, -1]
nba_test_y <- log(nba_test$Salario)

# Vemos la dimension de la matriz
dim(nba_train_x)

```



```{r}


train_control <- trainControl(method = "cv", number = 10)

caret_mod <- train(
  x = nba_train_x,
  y = nba_train_y,
  method = "glmnet",
  preProc = c("center", "scale", "zv", "nzv"),
  trControl = train_control,
  tuneLength = 10
)

caret_mod



```



```{r}
#Alfa es 0.7 por lo que aproximamos a alfa igual a 1
#Ponemos alfa, beta y obtenemos  el error

# x e y son la matriz modelo y el vector respuesta creados anteriormente con
# los datos de nba

#Modelo Lasso : permite superar su principal desventaja, la incapacidad de excluir predictores del modelo.
# fuerza a que las estimaciones de los coeficientes de los predictores tiendan a cero

modelos_lasso <- glmnet(x = nba_train_x, y = nba_train_y, alpha = 1)
plot(modelos_lasso, xvar = "lambda", label = TRUE)



```



```{r}


set.seed(1)
cv_error_lasso <- cv.glmnet(x = nba_train_x, y = nba_train_y, alpha = 1, nfolds = 10)
plot(cv_error_lasso)



```


```{r}

#es el valor de lambda con el que se consigue el minimo error 
cv_error_lasso$lambda.min


# lambda = 0.12
```



```{r}
#valor de lambda que tenemos que usar..... lambda = 0.21

cv_error_lasso$lambda.1se


```


```{r}

# Se reajusta el modelo con todas las observaciones empleando el valor de
# lambda óptimo


modelo_final_lasso <- cv.glmnet(x = nba_train_x, y = nba_train_y, alpha = 1)
coef(modelo_final_lasso)

##En dicho modelo, sólo se mantienen con un coeficiente superior a 0 las variables de edadt,minutos jugadosy WS
```

```{r}
min(modelo_final_lasso$cvm)



##lambda igual 1.12
```



```{r}

# media MSE para la muestra test:

prediccion<-predict(modelo_final_lasso, s=modelo_final_lasso$lambda.min, nba_test_x)
media_error_modelo<-mean(nba_test_y - prediccion)
media_error_modelo



``` 


```{r}
library(glmnet)
# x e y son la matriz modelo y el vector respuesta creados anteriormente con
# los datos de nba
cv_lasso <- cv.glmnet(x = nba_train_x, y = nba_train_y, alpha = 1)
min(cv_lasso$cvm)

pred <- predict(cv_lasso,s=cv_lasso$lambda.min,nba_test_x)
mean((nba_test_y-  pred)^2)

sqrt(1.160316)

#obtenemos un error de 1 millon de euros 
```


